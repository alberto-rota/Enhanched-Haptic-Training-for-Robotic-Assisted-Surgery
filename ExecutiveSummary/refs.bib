@generic{Goodrich2007,
   abstract = {Human-Robot Interaction (HRI) has recently received considerable attention in the academic community, in labs, in technology companies, and through the media. Because of this attention, it is desirable to present a survey of HRI to serve as a tutorial to people outside the field and to promote discussion of a unified vision of HRI within the field. The goal of this review is to present a unified treatment of HRI-related problems, to identify key themes, and discuss challenge problems that are likely to shape the field in the near future. Although the review follows a survey structure, the goal of presenting a coherent "story" of HRI means that there are necessarily some well-written, intriguing, and influential papers that are not referenced. Instead of trying to survey every paper, we describe the HRI story from multiple perspectives with an eye toward identifying themes that cross applications. The survey attempts to include papers that represent a fair cross section of the universities, government efforts, industry labs, and countries that contribute to HRI, and a cross section of the disciplines that contribute to the field, such as human, factors, robotics, cognitive psychology, and design.},
   author = {Michael A. Goodrich and Alan C. Schultz},
   doi = {10.1561/1100000005},
   issn = {15513955},
   issue = {3},
   journal = {Foundations and Trends in Human-Computer Interaction},
   pages = {203-275},
   title = {Human-robot interaction: A survey},
   volume = {1},
   year = {2007},
}

@article{Bowyer2014,
   abstract = {Active constraints, also known as virtual fixtures, are high-level control algorithms which can be used to assist a human in man-machine collaborative manipulation tasks. The active constraint controller monitors the robotic manipulator with respect to the environment and task, and anisotropically regulates the motion to provide assistance. The type of assistance offered by active constraints can vary, but they are typically used to either guide the user along a task-specific pathway or limit the user to within a "safe" region. There are several diverse methods described within the literature for applying active constraints, and these are surveyed within this paper. The active constraint research is described and compared using a simple generalized framework, which consists of three primary processes: 1) constraint definition, 2) constraint evaluation, and 3) constraint enforcement. All relevant research approaches for each of these processes, found using search terms associated to "virtual fixture, " "active constraint" and 'motion constraint,' are presented. © 2013 IEEE.},
   author = {Stuart A. Bowyer and Brian L. Davies and Ferdinando Rodriguez Y Baena},
   doi = {10.1109/TRO.2013.2283410},
   issn = {15523098},
   issue = {1},
   journal = {IEEE Transactions on Robotics},
   keywords = {Haptics and haptic interfaces,Impedance/admittance control,Medical robots and systems,Physical human-robot interaction,Telerobotics},
   pages = {138-157},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Active constraints/virtual fixtures: A survey},
   volume = {30},
   year = {2014},
}

@article{Bettini2004,
   abstract = {We present the design and implementation of a vision-based system for cooperative manipulation at millimeter to micrometer scales. The system is based on an admittance control algorithm that implements a broad class of guidance modes called virtual fixtures. A virtual fixture, like a real fixture, limits the motion of a tool to a prescribed class or range of motions. We describe how both hard (unyielding) and soft (yielding) virtual fixtures can be implemented in this control framework. We then detail the construction of virtual fixtures for point positioning and curve following as well as extensions of these to tubes, cones, and sequences thereof. We also describe an implemented system using the JHU Steady Hand Robot. The system uses computer vision as a sensor for providing a reference trajectory, and the virtual fixture control algorithm then provides haptic feedback to implemented direct, shared manipulation. We provide extensive experimental results detailing both system performance and the effects of virtual fixtures on human speed and accuracy. © 2004 IEEE.},
   author = {Alessandro Bettini and Panadda Marayong and Samuel Lang and Allison M. Okamura and Gregory D. Hager},
   doi = {10.1109/TRO.2004.829483},
   issn = {15523098},
   issue = {6},
   journal = {IEEE Transactions on Robotics},
   keywords = {Human-machine systems,Robot control,Virtual fixtures,Visual servoing},
   month = {12},
   pages = {953-966},
   title = {Vision-assisted control for manipulation using virtual fixtures},
   volume = {20},
   year = {2004},
}

@article{Ren2008,
   abstract = {Two-dimensional or 3-D visual guidance is often used for minimally invasive cardiac surgery and diagnosis. This visual guidance suffers from several drawbacks such as limited field of view, loss of signal from time to time, and in some cases, difficulty of interpretation. These limitations become more evident in beating-heart procedures when the surgeon has to perform a surgical procedure in the presence of heart motion. In this paper, we propose dynamic 3-D virtual fixtures (DVFs) to augment the visual guidance system with haptic feedback, to provide the surgeon with more helpful guidance by constraining the surgeon's hand motions thereby protecting sensitive structures. DVFs can be generated from preoperative dynamic magnetic resonance (MR) or computed tomograph (CT) images and then mapped to the patient during surgery. We have validated the feasibility of the proposed method on several simulated surgical tasks using a volunteer's cardiac image dataset. Validation results show that the integration of visual and haptic guidance can permit a user to perform surgical tasks more easily and with reduced error rate. We believe this is the first work presented in the field of virtual fixtures that explicitly considers heart motion. © 2008 IEEE.},
   author = {Jing Ren and Rajni V. Patel and Kenneth A. McIsaac and Gerard Guiraudon and Terry M. Peters},
   doi = {10.1109/TMI.2008.917246},
   issn = {02780062},
   issue = {8},
   journal = {IEEE Transactions on Medical Imaging},
   keywords = {Beating heart surgery,Dynamic virtual fixtures,Haptic feedback,Minimally invasive robot-assisted surgery},
   month = {8},
   pages = {1061-1070},
   pmid = {18672424},
   title = {Dynamic 3-D virtual fixtures for minimally invasive beating heart procedures},
   volume = {27},
   year = {2008},
}

@book{Kapoor2008,
   abstract = {Title from HTML table of contents (viewed June 19, 2008). "The 2008 IEEE International Conference on Robotics and Automation (ICRA 2008) will be held from May 19 -- May 23, 2008 at the Pasadena Conference Center in Pasadena, CA, USA. The theme of the conference is Human-Centered Robotics, the movement toward robotics technology that aids in the course of human everyday life"--Foreword.},
   author = {Ankur Kapoor and Russel H. Taylor},
   isbn = {9781424416479},
   publisher = {IEEE Xplore},
   title = {A Constrained Optimization Approach to Virtual Fixtures for Multi-Handed Tasks},
   year = {2008},
}

@generic{Bric2016,
   abstract = {Background: Worldwide, the annual number of robotic surgical procedures continues to increase. Robotic surgical skills are unique from those used in either open or laparoscopic surgery. The acquisition of a basic robotic surgical skill set may be best accomplished in the simulation laboratory. We sought to review the current literature pertaining to the use of virtual reality (VR) simulation in the acquisition of robotic surgical skills on the da Vinci Surgical System. Materials and methods: A PubMed search was conducted between December 2014 and January 2015 utilizing the following keywords: virtual reality, robotic surgery, da Vinci, da Vinci skills simulator, SimSurgery Educational Platform, Mimic dV-Trainer, and Robotic Surgery Simulator. Articles were included if they were published between 2007 and 2015, utilized VR simulation for the da Vinci Surgical System, and utilized a commercially available VR platform. Results: The initial search criteria returned 227 published articles. After all inclusion and exclusion criteria were applied, a total of 47 peer-reviewed manuscripts were included in the final review. Conclusions: There are many benefits to utilizing VR simulation for robotic skills acquisition. Four commercially available simulators have been demonstrated to be capable of assessing robotic skill. Three of the four simulators demonstrate the ability of a VR training curriculum to improve basic robotic skills, with proficiency-based training being the most effective training style. The skills obtained on a VR training curriculum are comparable with those obtained on dry laboratory simulation. The future of VR simulation includes utilization in assessment for re-credentialing purposes, advanced procedural-based training, and as a warm-up tool prior to surgery.},
   author = {Justin D. Bric and Derek C. Lumbard and Matthew J. Frelich and Jon C. Gould},
   doi = {10.1007/s00464-015-4517-y},
   issn = {14322218},
   issue = {6},
   journal = {Surgical Endoscopy},
   keywords = {Curriculum,Simulation,Training,Virtual reality,da Vinci Surgical System},
   month = {6},
   pages = {2169-2178},
   pmid = {26304107},
   publisher = {Springer New York LLC},
   title = {Current state of virtual reality simulation in robotic surgery training: a review},
   volume = {30},
   year = {2016},
}

@article{Lin2014,
   abstract = {Objective: Bone sawing or cutting is widely used for bone removal processes in bone surgery. It is an essential skill that surgeons should execute with a high level of experience and sensitive force perception. Surgical training simulators, with virtual and haptic feedback functions, can offer a safe, repeatable and cost-effective alternative to traditional surgeries. In this research, we developed a surgical training simulator with virtual and haptic force feedback for maxillofacial surgery, and we validated the effects on the learning of bone-sawing skills through empirical evaluation. Methods: Omega.6 from Force Dimension was employed as the haptic device, and Display300 from SenseGraphices was used as the 3D stereo display. The voxel-based model was constructed using computed tomography (CT) images, and the virtual tools were built through reverse engineering. The multi-point collision detection method was applied for haptic rendering to test the 3D relationship between the virtual tool and the bone voxels. Bone-sawing procedures in maxillofacial surgery were simulated with a virtual environment and real-time haptic feedback. A total of 25 participants (16 novices and 9 experienced surgeons) were included in 2 groups to perform the bone-sawing simulation for assessing the construct validity. Each of the participants completed the same bone-sawing procedure at the predefined maxillary region six times. For each trial, the sawing operative time, the maximal acceleration, and the percentage of the haptic force exceeding the threshold were recorded and analysed to evaluate the validity. After six trials, all of the participants scored the simulator in terms of safe force learning, stable hand control and overall performance to confirm the face validity. Moreover, 10 novices in 2 groups indentified the transfer validity on rapid prototype skull models by comparing the operative time and the maximal acceleration. Results: The analysed results of construct validity showed that the two groups significantly reduced their sawing operative times after six trials. Regarding maximal acceleration, the curve significantly descended and reached a plateau after the fifth repetition (novices) or third repetition (surgeons). Regarding safe haptic force, the novices obviously reduced the percentage of the haptic force exceeding the threshold, with statistical significance after four trials, but the surgeons did not show a significant difference. Moreover, the subjectively scored results demonstrated that the proposed simulator was more helpful for the novices than for the experienced surgeons, with scores of 8.31 and 7.22, respectively, for their overall performance. The experimental results on skill transference showed that the experimental group performed bone-sawing operation in lower maximal acceleration than control group with a significant difference (p<. 0.05). These findings suggested that the simulator training had positive effects on real sawing. Conclusions: The evaluation results proved the construct validity, face validity and the transfer validity of the simulator. These results indicated that this simulator was able to produce the effect of learning bone-sawing skill, and it could provide a training alternative for novices. © 2013 Elsevier Inc.},
   author = {Yanping Lin and Xudong Wang and Fule Wu and Xiaojun Chen and Chengtao Wang and Guofang Shen},
   doi = {10.1016/j.jbi.2013.12.010},
   issn = {15320464},
   journal = {Journal of Biomedical Informatics},
   keywords = {Bone sawing,Haptic,Simulator validation,Skill learning,Surgical training simulator},
   pages = {122-129},
   pmid = {24380817},
   publisher = {Academic Press Inc.},
   title = {Development and validation of a surgical training simulator with haptic feedback for learning bone-sawing skill},
   volume = {48},
   year = {2014},
}

@inproceedings{Enayati2018,
   abstract = {Hands-on training is an indispensable part of surgical practice. As the tools used in the operating room become more intricate, the demand for efficient training methods increases. This work proposes a robotic assistance-as-needed method for training with surgical teleoperated robots. The method adapts the intensity of the assistance according to the trainee's current and past performance while gradually increasing the level of control of the trainee as the training progresses. The work includes an experiment comprising 160 acquisition sessions from 16 novice subjects performing a bimanual teleoperated exercise with a da Vinci Research Kit surgical console. Results capture the subtleties in the task's learning curve with and without robotic assistance and hint at the potential of robotic assistance for complex visuomotor training. Although robotic assistance for motor learning has received mixed results that range from beneficial to detrimental effects, this study shows such assistance may increase the rate of learning of certain skills in complex motor tasks.},
   author = {Nima Enayati and Allison M. Okamura and Andrea Mariani and Edoardo Pellegrini and Margaret M. Coad and Giancarlo Ferrigno and Elena De Momi},
   doi = {10.1109/ICRA.2018.8463168},
   isbn = {9781538630815},
   issn = {10504729},
   journal = {Proceedings - IEEE International Conference on Robotics and Automation},
   month = {9},
   pages = {6631-6636},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Robotic Assistance-as-Needed for Enhanced Visuomotor Learning in Surgical Robotics Training: An Experimental Study},
   year = {2018},
}

@inproceedings{Kazanzidesf2014,
   abstract = {We present a telerobotics research platform that provides complete access to all levels of control via open-source electronics and software. The electronics employs an FPGA to enable a centralized computation and distributed I/O architecture in which all control computations are implemented in a familiar development environment (Linux PC) and low-latency I/O is performed over an IEEE-1394a (FireWire) bus at speeds up to 400 Mbits/sec. The mechanical components are obtained from retired first-generation da Vinci ® Surgical Systems. This system is currently installed at 11 research institutions, with additional installations underway, thereby creating a research community around a common open-source hardware and software platform.},
   author = {Peter Kazanzidesf and Zihan Chen and Anton Deguet and Gregory S. Fischer and Russell H. Taylor and Simon P. Dimaio},
   doi = {10.1109/ICRA.2014.6907809},
   isbn = {9781479936854},
   issn = {10504729},
   journal = {Proceedings - IEEE International Conference on Robotics and Automation},
   month = {9},
   pages = {6434-6439},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {An open-source research kit for the da Vinci® Surgical System},
   year = {2014},
}

@software{ros,
  author = {{Stanford Artificial Intelligence Laboratory et al.}},
  title = {Robotic Operating System},
  url = {https://www.ros.org},
  version = {ROS Melodic Morenia},
  date = {2018-05-23},
}

@article{Smith2014,
   abstract = {Background: There is a need for a standardized curriculum for training and assessment of robotic surgeons to proficiency, followed by high-stakes testing (HST) for certification. Methods: To standardize the curriculum and certification of robotic surgeons, a series of consensus conferences attended by 14 leading international surgical societies have been used to compile the outcomes measures and curriculum that should form the basis for a Fundamentals of Robotic Surgery (FRS) programme. Results: A set of 25 outcomes measures and a curriculum for teaching the skills needed to safely use current generation surgical robotic systems has been developed and accepted by a committee of experienced robotic surgeons across 14 specialties. Conclusions: A standardized process for certifying the skills of a robotic surgeon has begun to emerge. The work described here documents both the processes used for developing educational material and the educational content of a robotic curriculum.},
   author = {Roger Smith and Vipul Patel and Richard Satava},
   doi = {10.1002/rcs.1559},
   issn = {1478596X},
   issue = {3},
   journal = {International Journal of Medical Robotics and Computer Assisted Surgery},
   keywords = {Educational curriculum,Outcomes measures,Robotic surgery},
   month = {9},
   pages = {379-384},
   pmid = {24277315},
   publisher = {John Wiley and Sons Ltd},
   title = {Fundamentals of robotic surgery: A course of basic robotic surgery skills based upon a 14-society consensus template of outcomes measures and curriculum development},
   volume = {10},
   year = {2014},
}
